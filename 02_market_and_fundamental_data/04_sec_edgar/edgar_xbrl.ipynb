{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:root] *",
      "language": "python",
      "name": "conda-root-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "512px"
      },
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "edgar_xbrl.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tleitch/Machine-Learning-for-Algorithmic-Trading-Second-Edition/blob/master/02_market_and_fundamental_data/04_sec_edgar/edgar_xbrl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTAP8pHwacSF"
      },
      "source": [
        "# Working with filing data from the SEC's EDGAR service"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGyholJJj4N9",
        "outputId": "5fc7d3bb-7dc1-48cc-8157-341c1258b255",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install selenium\n",
        "!apt-get update # to update ubuntu to correctly run apt install\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
        "import sys\n",
        "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
        "from selenium import webdriver\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "wd = webdriver.Chrome('chromedriver',chrome_options=chrome_options)\n",
        "wd.get(\"https://www.webite-url.com\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: selenium in /usr/local/lib/python3.7/dist-packages (3.141.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from selenium) (1.24.3)\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:6 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Hit:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Hit:14 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "chromium-chromedriver is already the newest version (90.0.4430.93-0ubuntu0.18.04.1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 87 not upgraded.\n",
            "cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-17T09:43:34.785387Z",
          "start_time": "2020-06-17T09:43:34.782178Z"
        },
        "id": "m5ckdznMacSI"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-17T09:43:36.718588Z",
          "start_time": "2020-06-17T09:43:34.788206Z"
        },
        "scrolled": true,
        "id": "uPYQVS0zacSJ"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "from pathlib import Path\n",
        "from datetime import date\n",
        "import json\n",
        "from io import BytesIO\n",
        "from zipfile import ZipFile, BadZipFile\n",
        "import requests\n",
        "\n",
        "import pandas_datareader.data as web\n",
        "import pandas as pd\n",
        "\n",
        "from pprint import pprint\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as mticker"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-17T09:43:36.725846Z",
          "start_time": "2020-06-17T09:43:36.720298Z"
        },
        "scrolled": true,
        "id": "v0u9XwWracSK"
      },
      "source": [
        "sns.set_style('whitegrid')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-17T09:43:36.736625Z",
          "start_time": "2020-06-17T09:43:36.728071Z"
        },
        "id": "ULy6H3ZTacSK"
      },
      "source": [
        "data_path = Path('data') # perhaps set to external harddrive to accomodate large amount of data\n",
        "if not data_path.exists():\n",
        "    data_path.mkdir()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsUU7oC5acSK"
      },
      "source": [
        "## Download FS & Notes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0w0osW3acSL"
      },
      "source": [
        "The following code downloads and extracts all historical filings contained in the [Financial Statement and Notes](https://www.sec.gov/dera/data/financial-statement-and-notes-data-set.html) (FSN) datasets for the given range of quarters:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sToW0M79acSL"
      },
      "source": [
        "**Downloads over 40GB of data!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-17T09:43:36.748929Z",
          "start_time": "2020-06-17T09:43:36.738187Z"
        },
        "id": "wD18Ov4wacSL"
      },
      "source": [
        "SEC_URL = 'https://www.sec.gov/'\n",
        "FSN_PATH = 'files/dera/data/financial-statement-and-notes-data-sets/'"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-17T09:43:36.756896Z",
          "start_time": "2020-06-17T09:43:36.750569Z"
        },
        "id": "PPPilnNaacSM"
      },
      "source": [
        "today = pd.Timestamp(date.today())\n",
        "this_year = today.year\n",
        "this_quarter = today.quarter\n",
        "past_years = range(2014, this_year)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-17T09:43:36.764906Z",
          "start_time": "2020-06-17T09:43:36.759443Z"
        },
        "id": "l-BC6r6-acSM"
      },
      "source": [
        "filing_periods = [(y, q) for y in past_years for q in range(1, 5)]\n",
        "filing_periods.extend([(this_year, q) for q in range(1, this_quarter + 1)])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-17T09:55:22.826190Z",
          "start_time": "2020-06-17T09:43:36.766942Z"
        },
        "id": "0u4Y8R5uacSM",
        "outputId": "0d272f39-d01f-48eb-c497-52d215d14d77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        }
      },
      "source": [
        "for i, (yr, qtr) in enumerate(filing_periods[-4: -3], 1):\n",
        "    print(f'{yr}-Q{qtr}', end=' ', flush=True)\n",
        "    filing = f'{yr}q{qtr}_notes.zip'\n",
        "    path = data_path / f'{yr}_{qtr}' / 'source'\n",
        "    if not path.exists():\n",
        "        path.mkdir(exist_ok=True, parents=True)\n",
        "    url = SEC_URL + FSN_PATH + filing\n",
        "    \n",
        "    # 2020q1 is currently (Oct 2020) in a different location; this may change at some point\n",
        "    if yr == 2020 and qtr == 1:\n",
        "        url = SEC_URL + 'files/node/add/data_distribution/' + filing\n",
        "    response = requests.get().content\n",
        "    try:\n",
        "        with ZipFile(BytesIO(response)) as zip_file:\n",
        "            for file in zip_file.namelist():\n",
        "                local_file = path / file\n",
        "                if local_file.exists():\n",
        "                    continue\n",
        "                with local_file.open('wb') as output:\n",
        "                    for line in zip_file.open(file).readlines():\n",
        "                        output.write(line)\n",
        "    except BadZipFile:\n",
        "        'https://www.sec.gov/files/node/add/data_distribution/2020q1_notes.zip'\n",
        "        print('got bad zip file')\n",
        "        continue"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-Q3 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-029cf2be5f0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0myr\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2020\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mqtr\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSEC_URL\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'files/node/add/data_distribution/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfiling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzip_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: get() missing 1 required positional argument: 'url'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oz3R-2O5acSN"
      },
      "source": [
        "## Save to parquet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naluR9-_acSO"
      },
      "source": [
        "The data is fairly large and to enable faster access than the original text files permit, it is better to convert the text files to binary, columnar parquet format (see Section 'Efficient data storage with pandas' in chapter 2 for a performance comparison of various data-storage options compatible with pandas DataFrames):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-17T10:24:34.700791Z",
          "start_time": "2020-06-17T09:55:22.827490Z"
        },
        "scrolled": true,
        "id": "zW_gE5_tacSO"
      },
      "source": [
        "for f in data_path.glob('**/*.tsv'):\n",
        "    file_name = f.stem  + '.parquet'\n",
        "    path = Path(f.parents[1]) / 'parquet'\n",
        "    if (path / file_name).exists():\n",
        "        continue\n",
        "    if not path.exists():\n",
        "        path.mkdir(exist_ok=True)\n",
        "    try:\n",
        "        df = pd.read_csv(f, sep='\\t', encoding='latin1', low_memory=False)\n",
        "    except:\n",
        "        print(f)\n",
        "    df.to_parquet(path / file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_s2nr6swacSO"
      },
      "source": [
        "## Metadata json"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-17T10:24:34.964410Z",
          "start_time": "2020-06-17T10:24:34.702404Z"
        },
        "scrolled": true,
        "id": "GRyqtMRfacSO",
        "outputId": "8f75acd0-7d65-4a2e-e2f0-4a1c06c5941c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        }
      },
      "source": [
        "file = data_path / '2018_3' / 'source' / '2018q3_notes-metadata.json'\n",
        "with file.open() as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "pprint(data)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-f97901727350>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_path\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m'2018_3'\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m'source'\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m'2018q3_notes-metadata.json'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/pathlib.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, mode, buffering, encoding, errors, newline)\u001b[0m\n\u001b[1;32m   1206\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1207\u001b[0m         return io.open(self, mode, buffering, encoding, errors, newline,\n\u001b[0;32m-> 1208\u001b[0;31m                        opener=self._opener)\n\u001b[0m\u001b[1;32m   1209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/pathlib.py\u001b[0m in \u001b[0;36m_opener\u001b[0;34m(self, name, flags, mode)\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0o666\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m         \u001b[0;31m# A stub for the opener argument to built-in open()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_raw_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0o777\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/2018_3/source/2018q3_notes-metadata.json'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UB1LPoX_acSP"
      },
      "source": [
        "## Data Organization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjWnfKEoacSP"
      },
      "source": [
        "For each quarter, the FSN data is organized into eight file sets that contain information about submissions, numbers, taxonomy tags, presentation, and more. Each dataset consists of rows and fields and is provided as a tab-delimited text file:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTBk4LACacSP"
      },
      "source": [
        "| File | Dataset      | Description                                                 |\n",
        "|------|--------------|-------------------------------------------------------------|\n",
        "| SUB  | Submission   | Identifies each XBRL submission by company, form, date, etc |\n",
        "| TAG  | Tag          | Defines and explains each taxonomy tag                      |\n",
        "| DIM  | Dimension    | Adds detail to numeric and plain text data                  |\n",
        "| NUM  | Numeric      | One row for each distinct data point in filing              |\n",
        "| TXT  | Plain Text   | Contains all non-numeric XBRL fields                        |\n",
        "| REN  | Rendering    | Information for rendering on SEC website                    |\n",
        "| PRE  | Presentation | Detail on tag and number presentation in primary statements |\n",
        "| CAL  | Calculation  | Shows arithmetic relationships among tags                   |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eECTKHA8acSQ"
      },
      "source": [
        "## Submission Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7VH6N-5acSQ"
      },
      "source": [
        "The latest submission file contains around 6,500 entries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-17T10:24:35.263944Z",
          "start_time": "2020-06-17T10:24:34.965654Z"
        },
        "id": "zAKzXbuWacSQ"
      },
      "source": [
        "sub = pd.read_parquet(data_path / '2018_3' / 'parquet' / 'sub.parquet')\n",
        "sub.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQ_bhb6BacSR"
      },
      "source": [
        "### Get AAPL submission"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBkqG4Z5acSR"
      },
      "source": [
        "The submission dataset contains the unique identifiers required to retrieve the filings: the Central Index Key (CIK) and the Accession Number (adsh). The following shows some of the information about Apple's 2018Q1 10-Q filing:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-17T10:24:35.282027Z",
          "start_time": "2020-06-17T10:24:35.265241Z"
        },
        "scrolled": true,
        "id": "NNgoG6-UacSR"
      },
      "source": [
        "name = 'APPLE INC'\n",
        "apple = sub[sub.name == name].T.dropna().squeeze()\n",
        "key_cols = ['name', 'adsh', 'cik', 'name', 'sic', 'countryba', 'stprba',\n",
        "            'cityba', 'zipba', 'bas1', 'form', 'period', 'fy', 'fp', 'filed']\n",
        "apple.loc[key_cols]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qs7OTMDjacSS"
      },
      "source": [
        "## Build AAPL fundamentals dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbWIBliiacSS"
      },
      "source": [
        "Using the central index key, we can identify all historical quarterly filings available for Apple, and combine this information to obtain 26 Forms 10-Q and nine annual Forms 10-K."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezE7wApbacSS"
      },
      "source": [
        "### Get filings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-17T10:24:36.521152Z",
          "start_time": "2020-06-17T10:24:35.283775Z"
        },
        "scrolled": true,
        "id": "Ny21ZYtQacSS"
      },
      "source": [
        "aapl_subs = pd.DataFrame()\n",
        "for sub in data_path.glob('**/sub.parquet'):\n",
        "    sub = pd.read_parquet(sub)\n",
        "    aapl_sub = sub[(sub.cik.astype(int) == apple.cik) & (sub.form.isin(['10-Q', '10-K']))]\n",
        "    aapl_subs = pd.concat([aapl_subs, aapl_sub])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UslGdf6ZacSS"
      },
      "source": [
        "We find 15 quarterly 10-Q and 4 annual 10-K reports:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-17T10:24:36.543920Z",
          "start_time": "2020-06-17T10:24:36.522618Z"
        },
        "scrolled": true,
        "id": "wQTNdxPsacST"
      },
      "source": [
        "aapl_subs.form.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWUvC71gacST"
      },
      "source": [
        "### Get numerical filing data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9J3eNH8CacST"
      },
      "source": [
        "With the Accession Number for each filing, we can now rely on the taxonomies to select the appropriate XBRL tags (listed in the TAG file) from the NUM and TXT files to obtain the numerical or textual/footnote data points of interest."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTiVE_MKacST"
      },
      "source": [
        "First, let's extract all numerical data available from the 19 Apple filings:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-17T10:26:39.700986Z",
          "start_time": "2020-06-17T10:24:36.545544Z"
        },
        "id": "EPLBGTHCacST"
      },
      "source": [
        "aapl_nums = pd.DataFrame()\n",
        "for num in data_path.glob('**/num.parquet'):\n",
        "    num = pd.read_parquet(num).drop('dimh', axis=1)\n",
        "    aapl_num = num[num.adsh.isin(aapl_subs.adsh)]\n",
        "    print(len(aapl_num))\n",
        "    aapl_nums = pd.concat([aapl_nums, aapl_num])\n",
        "aapl_nums.ddate = pd.to_datetime(aapl_nums.ddate, format='%Y%m%d')   \n",
        "aapl_nums.to_parquet(data_path / 'aapl_nums.parquet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xg0VHN1gacSU"
      },
      "source": [
        "In total, the nine years of filing history provide us with over 18,000 numerical values for AAPL."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-17T10:26:39.743882Z",
          "start_time": "2020-06-17T10:26:39.702611Z"
        },
        "scrolled": true,
        "id": "-FuNxM3iacSU"
      },
      "source": [
        "aapl_nums.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UitjJzDLacSU"
      },
      "source": [
        "## Create P/E Ratio from EPS and stock price data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTKD3DCDacSU"
      },
      "source": [
        "We can select a useful field, such as Earnings per Diluted Share (EPS), that we can combine with market data to calculate the popular Price/Earnings (P/E) valuation ratio."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-17T10:26:39.749424Z",
          "start_time": "2020-06-17T10:26:39.745293Z"
        },
        "id": "snfiJlodacSU"
      },
      "source": [
        "stock_split = 7\n",
        "split_date = pd.to_datetime('20140604')\n",
        "split_date"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8TgzEB_acSV"
      },
      "source": [
        "We do need to take into account, however, that Apple split its stock 7:1 on June 4, 2014, and Adjusted Earnings per Share before the split to make earnings comparable, as illustrated in the following code block:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-17T10:26:39.960502Z",
          "start_time": "2020-06-17T10:26:39.750697Z"
        },
        "id": "0TMaJ7ywacSV"
      },
      "source": [
        "# Filter by tag; keep only values measuring 1 quarter\n",
        "eps = aapl_nums[(aapl_nums.tag == 'EarningsPerShareDiluted')\n",
        "                & (aapl_nums.qtrs == 1)].drop('tag', axis=1)\n",
        "\n",
        "# Keep only most recent data point from each filing\n",
        "eps = eps.groupby('adsh').apply(lambda x: x.nlargest(n=1, columns=['ddate']))\n",
        "\n",
        "# Adjust earnings prior to stock split downward\n",
        "eps.loc[eps.ddate < split_date,'value'] = eps.loc[eps.ddate < split_date, 'value'].div(7)\n",
        "eps = eps[['ddate', 'value']].set_index('ddate').squeeze().sort_index()\n",
        "eps = eps.rolling(4,min_periods=4).sum().dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-17T10:26:40.874010Z",
          "start_time": "2020-06-17T10:26:39.961904Z"
        },
        "id": "2Rkl6r5FacSV"
      },
      "source": [
        "eps.plot(lw=2, figsize=(14, 6), title='Diluted Earnings per Share')\n",
        "plt.xlabel('')\n",
        "plt.savefig('diluted eps', dps=300);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-17T10:26:41.388519Z",
          "start_time": "2020-06-17T10:26:40.880740Z"
        },
        "id": "fnWHgyIracSV"
      },
      "source": [
        "symbol = 'AAPL.US'\n",
        "\n",
        "aapl_stock = (web.\n",
        "              DataReader(symbol, 'quandl', start=eps.index.min())\n",
        "              .resample('D')\n",
        "              .last()\n",
        "             .loc['2014':eps.index.max()])\n",
        "aapl_stock.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-17T10:26:42.638189Z",
          "start_time": "2020-06-17T10:26:41.391885Z"
        },
        "id": "yDjelZVLacSW"
      },
      "source": [
        "pe = aapl_stock.AdjClose.to_frame('price').join(eps.to_frame('eps'))\n",
        "pe = pe.fillna(method='ffill').dropna()\n",
        "pe['P/E Ratio'] = pe.price.div(pe.eps)\n",
        "pe['P/E Ratio'].plot(lw=2, figsize=(14, 6), title='TTM P/E Ratio');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-17T10:26:42.683358Z",
          "start_time": "2020-06-17T10:26:42.669431Z"
        },
        "id": "KRKNyVa6acSW"
      },
      "source": [
        "pe.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-17T10:26:45.368067Z",
          "start_time": "2020-06-17T10:26:42.696994Z"
        },
        "id": "mThG_yoUacSW"
      },
      "source": [
        "axes = pe.plot(subplots=True, figsize=(16,8), legend=False, lw=2)\n",
        "axes[0].set_title('Adj. Close Price')\n",
        "axes[1].set_title('Diluted Earnings per Share')\n",
        "axes[2].set_title('Trailing P/E Ratio')\n",
        "plt.tight_layout();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbBWAZ8aacSW"
      },
      "source": [
        "## Explore Additional Fields"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69cOJ_IDacSX"
      },
      "source": [
        "The field `tag` references values defined in the taxonomy:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-17T10:26:45.384722Z",
          "start_time": "2020-06-17T10:26:45.373605Z"
        },
        "id": "-29K0g3oacSX",
        "outputId": "37a4e0a2-9ce4-42b8-a446-8ce02847d7d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        }
      },
      "source": [
        "aapl_nums.tag.value_counts()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-fe1253871a19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maapl_nums\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'aapl_nums' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIqQnFQ4acSX"
      },
      "source": [
        "We can select values of interest and track their value or use them as inputs to compute fundamental metrics like the Dividend/Share ratio."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVYzdwYmacSX"
      },
      "source": [
        "### Dividends per Share"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-17T10:26:45.399406Z",
          "start_time": "2020-06-17T10:26:45.386515Z"
        },
        "scrolled": true,
        "id": "SFJg3VDracSX"
      },
      "source": [
        "fields = ['EarningsPerShareDiluted',\n",
        "          'PaymentsOfDividendsCommonStock',\n",
        "          'WeightedAverageNumberOfDilutedSharesOutstanding',\n",
        "          'OperatingIncomeLoss',\n",
        "          'NetIncomeLoss',\n",
        "          'GrossProfit']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-17T10:26:45.761291Z",
          "start_time": "2020-06-17T10:26:45.400903Z"
        },
        "id": "4pHsIdUIacSX"
      },
      "source": [
        "dividends = (aapl_nums\n",
        "             .loc[aapl_nums.tag == 'PaymentsOfDividendsCommonStock', ['ddate', 'value']]\n",
        "             .groupby('ddate')\n",
        "             .mean())\n",
        "shares = (aapl_nums\n",
        "          .loc[aapl_nums.tag == 'WeightedAverageNumberOfDilutedSharesOutstanding', ['ddate', 'value']]\n",
        "          .drop_duplicates()\n",
        "          .groupby('ddate')\n",
        "          .mean())\n",
        "df = dividends.div(shares).dropna()\n",
        "ax = df.plot.bar(figsize=(14, 5), title='Dividends per Share', legend=False)\n",
        "ax.xaxis.set_major_formatter(mticker.FixedFormatter(df.index.strftime('%Y-%m')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVUGK-bRacSY"
      },
      "source": [
        "## Bonus: Textual Information"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-17T10:26:47.996396Z",
          "start_time": "2020-06-17T10:26:45.773445Z"
        },
        "scrolled": true,
        "id": "qmeEJSRracSY"
      },
      "source": [
        "txt = pd.read_parquet(data_path / '2016_2' / 'parquet' /  'txt.parquet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3_S0tiRacSY"
      },
      "source": [
        "AAPL's adsh is not avaialble in the txt file but you can obtain notes from the financial statesments here:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-17T10:26:48.023203Z",
          "start_time": "2020-06-17T10:26:47.997594Z"
        },
        "id": "C-D7E8MLacSY"
      },
      "source": [
        "txt.head()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}