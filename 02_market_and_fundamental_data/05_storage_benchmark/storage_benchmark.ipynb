{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": true,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    },
    "colab": {
      "name": "storage_benchmark.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tleitch/Machine-Learning-for-Algorithmic-Trading-Second-Edition/blob/master/02_market_and_fundamental_data/05_storage_benchmark/storage_benchmark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKLfITSSambW"
      },
      "source": [
        "# Storage Benchmark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTv1rZ3kambY"
      },
      "source": [
        "In this notebook, we'll compare the following storage formats:\n",
        "- CSV: Comma-separated, standard flat text file format.\n",
        "- HDF5: Hierarchical data format, developed initially at the National Center for Supercomputing Applications. It is a fast and scalable storage format for numerical data, available in pandas using the PyTables library.\n",
        "- Parquet: Part of the Apache Hadoop ecosystem, a binary, columnar storage format that provides efficient data compression and encoding and has been developed by Cloudera and Twitter. It is available for pandas through the `pyarrow` library, led by Wes McKinney, the original author of pandas.\n",
        "\n",
        "This notebook compares the performance of the preceding libraries using a test DataFrame that can be configured to contain numerical or text data, or both. For the HDF5 library, we test both the fixed and table formats. The table format allows for queries and can be appended to.\n",
        "\n",
        "## Usage\n",
        "\n",
        "To recreate the charts used in the book, you need to run this notebook twice up to section 'Store Result' using different settings for `data_type` and arguments for `generate_test_data` as follows:\n",
        "1. `data_type='Numeric`: `numerical_cols=2000`, `text_cols=0` (default)\n",
        "2. `data_type='Mixed`: `numerical_cols=1000`, `text_cols=1000`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYYpr3QIambZ"
      },
      "source": [
        "## Imports & Settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-17T01:35:27.316285Z",
          "start_time": "2020-06-17T01:35:27.312369Z"
        },
        "id": "oQEBuzLOambZ"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-17T01:35:28.969546Z",
          "start_time": "2020-06-17T01:35:27.319259Z"
        },
        "pycharm": {
          "is_executing": true
        },
        "id": "6zZxMGPramba"
      },
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import random\n",
        "import string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-17T01:35:28.996443Z",
          "start_time": "2020-06-17T01:35:28.990967Z"
        },
        "pycharm": {
          "is_executing": true
        },
        "id": "Ecquoqzvamba"
      },
      "source": [
        "sns.set_style('whitegrid')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-17T01:35:29.007566Z",
          "start_time": "2020-06-17T01:35:29.000677Z"
        },
        "pycharm": {
          "is_executing": true
        },
        "id": "cMP_fqqYambb"
      },
      "source": [
        "results = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKLRW351ambb"
      },
      "source": [
        "## Generate Test Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SNC45nnambb"
      },
      "source": [
        "The test `DataFrame` that can be configured to contain numerical or text data, or both. For the HDF5 library, we test both the fixed and table format. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-17T01:35:29.019361Z",
          "start_time": "2020-06-17T01:35:29.012349Z"
        },
        "pycharm": {
          "is_executing": true
        },
        "id": "c2XUEGeoambb"
      },
      "source": [
        "def generate_test_data(nrows=100000, numerical_cols=2000, text_cols=0, text_length=10):\n",
        "    s = \"\".join([random.choice(string.ascii_letters)\n",
        "                 for _ in range(text_length)])\n",
        "    data = pd.concat([pd.DataFrame(np.random.random(size=(nrows, numerical_cols))),\n",
        "                      pd.DataFrame(np.full(shape=(nrows, text_cols), fill_value=s))],\n",
        "                     axis=1, ignore_index=True)\n",
        "    data.columns = [str(i) for i in data.columns]\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-17T01:35:29.041894Z",
          "start_time": "2020-06-17T01:35:29.024486Z"
        },
        "pycharm": {
          "is_executing": true
        },
        "id": "cLQ-cZstambc"
      },
      "source": [
        "data_type = 'Numeric'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-17T01:36:22.452175Z",
          "start_time": "2020-06-17T01:35:29.057271Z"
        },
        "pycharm": {
          "is_executing": true
        },
        "id": "W12Qec5_ambc",
        "outputId": "ca4994b6-6a4f-4e6b-a587-63a00fed93b6"
      },
      "source": [
        "df = generate_test_data(numerical_cols=1000, text_cols=1000)\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100000 entries, 0 to 99999\n",
            "Columns: 2000 entries, 0 to 1999\n",
            "dtypes: float64(1000), object(1000)\n",
            "memory usage: 1.5+ GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48ebdad2ambd"
      },
      "source": [
        "## Parquet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiBq8KwAambd"
      },
      "source": [
        "### Size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-17T01:36:22.456279Z",
          "start_time": "2020-06-17T01:36:22.453955Z"
        },
        "pycharm": {
          "is_executing": true
        },
        "id": "FeDQFupLambd"
      },
      "source": [
        "parquet_file = Path('test.parquet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-17T01:37:07.069924Z",
          "start_time": "2020-06-17T01:36:22.457639Z"
        },
        "pycharm": {
          "is_executing": true
        },
        "id": "iZTf51stambd"
      },
      "source": [
        "df.to_parquet(parquet_file)\n",
        "size = parquet_file.stat().st_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itM0T21vambe"
      },
      "source": [
        "### Read"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-17T01:37:48.957149Z",
          "start_time": "2020-06-17T01:37:07.076984Z"
        },
        "pycharm": {
          "is_executing": true
        },
        "id": "tqEAYhxPambe",
        "outputId": "ac585c8d-5fb1-4378-d777-5759ee71fa7f"
      },
      "source": [
        "%%timeit -o\n",
        "df = pd.read_parquet(parquet_file)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4.86 s ± 134 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TimeitResult : 4.86 s ± 134 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-17T01:37:48.961665Z",
          "start_time": "2020-06-17T01:37:48.958800Z"
        },
        "pycharm": {
          "is_executing": true
        },
        "scrolled": true,
        "id": "IDI6g-eEambe"
      },
      "source": [
        "read = _"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-17T01:37:49.188464Z",
          "start_time": "2020-06-17T01:37:48.963287Z"
        },
        "pycharm": {
          "is_executing": true
        },
        "id": "S26gwEPzambe"
      },
      "source": [
        "parquet_file.unlink()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgxBBvlYambf"
      },
      "source": [
        "### Write"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-17T01:43:39.425369Z",
          "start_time": "2020-06-17T01:37:49.190219Z"
        },
        "pycharm": {
          "is_executing": true
        },
        "id": "99Ru6MGDambf",
        "outputId": "3b4b4eb4-e618-40f7-a5bd-5f0830e9dde1"
      },
      "source": [
        "%%timeit -o\n",
        "df.to_parquet(parquet_file)\n",
        "parquet_file.unlink()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "43.5 s ± 1.13 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TimeitResult : 43.5 s ± 1.13 s per loop (mean ± std. dev. of 7 runs, 1 loop each)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-17T01:43:39.428982Z",
          "start_time": "2020-06-17T01:43:39.426799Z"
        },
        "pycharm": {
          "is_executing": true
        },
        "id": "pXHiERteambf"
      },
      "source": [
        "write = _"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mL97MtRkambf"
      },
      "source": [
        "### Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-17T01:43:39.439864Z",
          "start_time": "2020-06-17T01:43:39.430333Z"
        },
        "pycharm": {
          "is_executing": true
        },
        "id": "1fpGBm69ambf"
      },
      "source": [
        "results['Parquet'] = {'read': np.mean(read.all_runs), 'write': np.mean(write.all_runs), 'size': size}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Iaycjdrambg"
      },
      "source": [
        "## HDF5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-17T01:43:39.448675Z",
          "start_time": "2020-06-17T01:43:39.441367Z"
        },
        "pycharm": {
          "is_executing": true
        },
        "id": "EVcnfQQiambg"
      },
      "source": [
        "test_store = Path('index.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCnxRggyambg"
      },
      "source": [
        "### Fixed Format"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGDbK1Ocambg"
      },
      "source": [
        "#### Size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-17T01:44:50.784125Z",
          "start_time": "2020-06-17T01:43:39.450005Z"
        },
        "pycharm": {
          "is_executing": true
        },
        "id": "otx80Twpambg"
      },
      "source": [
        "with pd.HDFStore(test_store) as store:\n",
        "    store.put('file', df)\n",
        "size = test_store.stat().st_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KLhxL7mambg"
      },
      "source": [
        "#### Read"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-17T02:01:51.204424Z",
          "start_time": "2020-06-17T01:44:50.785606Z"
        },
        "pycharm": {
          "is_executing": true
        },
        "id": "vhmMXYCBambh",
        "outputId": "c7973f0b-52f7-4f35-a7df-c1a1c2ced9c0"
      },
      "source": [
        "%%timeit -o\n",
        "with pd.HDFStore(test_store) as store:\n",
        "    store.get('file')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2min 7s ± 2.73 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TimeitResult : 2min 7s ± 2.73 s per loop (mean ± std. dev. of 7 runs, 1 loop each)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-17T02:01:51.211964Z",
          "start_time": "2020-06-17T02:01:51.208706Z"
        },
        "pycharm": {
          "is_executing": true
        },
        "id": "XvRHzj38ambh"
      },
      "source": [
        "read = _"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-17T02:01:51.620046Z",
          "start_time": "2020-06-17T02:01:51.216720Z"
        },
        "pycharm": {
          "is_executing": true
        },
        "id": "7r98eO62ambh"
      },
      "source": [
        "test_store.unlink()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjaldGh3ambh"
      },
      "source": [
        "#### Write"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-17T02:11:19.164517Z",
          "start_time": "2020-06-17T02:01:51.627442Z"
        },
        "pycharm": {
          "is_executing": true
        },
        "id": "oymRwU7Fambh",
        "outputId": "88194c5d-4966-4acc-b739-54d630be9597"
      },
      "source": [
        "%%timeit -o\n",
        "with pd.HDFStore(test_store) as store:\n",
        "    store.put('file', df)\n",
        "test_store.unlink()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1min 10s ± 1.47 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TimeitResult : 1min 10s ± 1.47 s per loop (mean ± std. dev. of 7 runs, 1 loop each)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-17T02:11:19.168656Z",
          "start_time": "2020-06-17T02:11:19.166433Z"
        },
        "pycharm": {
          "is_executing": true
        },
        "id": "Q_SvhE5rambi"
      },
      "source": [
        "write = _"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzHiiKZ-ambi"
      },
      "source": [
        "#### Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-17T02:11:19.182992Z",
          "start_time": "2020-06-17T02:11:19.170082Z"
        },
        "pycharm": {
          "is_executing": true
        },
        "id": "rvLiN-JAambi"
      },
      "source": [
        "results['HDF Fixed'] = {'read': np.mean(read.all_runs), 'write': np.mean(write.all_runs), 'size': size}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqlAtautambi"
      },
      "source": [
        "### Table Format"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcfllVyiambi"
      },
      "source": [
        "#### Size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-17T02:15:33.776631Z",
          "start_time": "2020-06-17T02:11:19.184371Z"
        },
        "pycharm": {
          "is_executing": true
        },
        "id": "hqMZ7F1Lambj"
      },
      "source": [
        "with pd.HDFStore(test_store) as store:\n",
        "    store.append('file', df, format='t')\n",
        "size = test_store.stat().st_size    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GrhKAOPambj"
      },
      "source": [
        "#### Read"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2020-06-17T01:35:27.475Z"
        },
        "pycharm": {
          "is_executing": true
        },
        "id": "anXSMqyGambj"
      },
      "source": [
        "%%timeit -o\n",
        "with pd.HDFStore(test_store) as store:\n",
        "    df = store.get('file')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2020-06-17T01:35:27.484Z"
        },
        "pycharm": {
          "is_executing": true
        },
        "id": "GpYD0j42ambj"
      },
      "source": [
        "read = _"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2020-06-17T01:35:27.491Z"
        },
        "pycharm": {
          "is_executing": true
        },
        "id": "ehaASlYbambj"
      },
      "source": [
        "test_store.unlink()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cC6BsMLxambj"
      },
      "source": [
        "#### Write"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OU82XIxOambk"
      },
      "source": [
        "Note that `write` in table format does not work with text data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2020-06-17T01:35:27.499Z"
        },
        "pycharm": {
          "is_executing": true
        },
        "id": "KEoypytuambk"
      },
      "source": [
        "%%timeit -o\n",
        "with pd.HDFStore(test_store) as store:\n",
        "    store.append('file', df, format='t')\n",
        "test_store.unlink()    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2020-06-17T01:35:27.507Z"
        },
        "pycharm": {
          "is_executing": true
        },
        "id": "kcE_cSBeambk"
      },
      "source": [
        "write = _"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edEGVdcaambk"
      },
      "source": [
        "#### Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2020-06-17T01:35:27.515Z"
        },
        "pycharm": {
          "is_executing": true
        },
        "id": "5dC2fZoKambk"
      },
      "source": [
        "results['HDF Table'] = {'read': np.mean(read.all_runs), 'write': np.mean(write.all_runs), 'size': size}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cc4pHHm6ambk"
      },
      "source": [
        "### Table Select"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzrFkpiRambk"
      },
      "source": [
        "#### Size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2020-06-17T01:35:27.527Z"
        },
        "pycharm": {
          "is_executing": true
        },
        "id": "dq14DzcSambl"
      },
      "source": [
        "with pd.HDFStore(test_store) as store:\n",
        "    store.append('file', df, format='t', data_columns=['company', 'form'])\n",
        "size = test_store.stat().st_size "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDQS8M3gambl"
      },
      "source": [
        "#### Read"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2020-06-17T01:35:27.531Z"
        },
        "pycharm": {
          "is_executing": true
        },
        "id": "ZVPENI8Uambl"
      },
      "source": [
        "company = 'APPLE INC'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2020-06-17T01:35:27.535Z"
        },
        "pycharm": {
          "is_executing": true
        },
        "id": "OVI6HbU7ambl"
      },
      "source": [
        "%%timeit\n",
        "with pd.HDFStore(test_store) as store:\n",
        "    s = store.get('file')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2020-06-17T01:35:27.551Z"
        },
        "pycharm": {
          "is_executing": true
        },
        "id": "6v0ttpFxambl"
      },
      "source": [
        "read = _"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2020-06-17T01:35:27.554Z"
        },
        "pycharm": {
          "is_executing": true
        },
        "id": "M25IDRRCambl"
      },
      "source": [
        "test_store.unlink()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPj-t_lhambm"
      },
      "source": [
        "#### Write"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2020-06-17T01:35:27.572Z"
        },
        "pycharm": {
          "is_executing": true
        },
        "id": "h5yhww82ambm"
      },
      "source": [
        "%%timeit\n",
        "with pd.HDFStore(test_store) as store:\n",
        "    store.append('file', df, format='t', data_columns=['company', 'form'])\n",
        "test_store.unlink() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2020-06-17T01:35:27.575Z"
        },
        "pycharm": {
          "is_executing": true
        },
        "id": "FWYQVJzzambm"
      },
      "source": [
        "write = _"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgQ1plx8ambm"
      },
      "source": [
        "#### Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2020-06-17T01:35:27.579Z"
        },
        "pycharm": {
          "is_executing": true
        },
        "id": "AajlJItGambm"
      },
      "source": [
        "results['HDF Select'] = {'read': np.mean(read.all_runs), 'write': np.mean(write.all_runs), 'size': size}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMt2BHUXambn"
      },
      "source": [
        "## CSV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2020-06-17T01:35:27.583Z"
        },
        "pycharm": {
          "is_executing": true
        },
        "id": "7RTe0joVambn"
      },
      "source": [
        "test_csv = Path('test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXOBRhd1ambn"
      },
      "source": [
        "### Size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2020-06-17T01:35:27.587Z"
        },
        "pycharm": {
          "is_executing": true
        },
        "id": "z0QZ4VSjambn"
      },
      "source": [
        "df.to_csv(test_csv)\n",
        "test_csv.stat().st_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTcq1MV2ambn"
      },
      "source": [
        "### Read"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2020-06-17T01:35:27.592Z"
        },
        "pycharm": {
          "is_executing": true
        },
        "id": "aBvAxeO0ambn"
      },
      "source": [
        "%%timeit -o\n",
        "df = pd.read_csv(test_csv)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2020-06-17T01:35:27.596Z"
        },
        "pycharm": {
          "is_executing": true
        },
        "id": "b_caYMQ7ambo"
      },
      "source": [
        "read = _"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2020-06-17T01:35:27.600Z"
        },
        "pycharm": {
          "is_executing": true
        },
        "id": "nbedaqVVambo"
      },
      "source": [
        "test_csv.unlink()  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kq6jbi6Nambo"
      },
      "source": [
        "### Write"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2020-06-17T01:35:27.605Z"
        },
        "pycharm": {
          "is_executing": true
        },
        "id": "z1Vb9yp0ambo"
      },
      "source": [
        "%%timeit -o\n",
        "df.to_csv(test_csv)\n",
        "test_csv.unlink()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2020-06-17T01:35:27.616Z"
        },
        "pycharm": {
          "is_executing": true
        },
        "id": "4FO6NKEQambo"
      },
      "source": [
        "write = _"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uICFj86ambo"
      },
      "source": [
        "### Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2020-06-17T01:35:27.621Z"
        },
        "pycharm": {
          "is_executing": true
        },
        "id": "5-94VEujambp"
      },
      "source": [
        "results['CSV'] = {'read': np.mean(read.all_runs), 'write': np.mean(write.all_runs), 'size': size}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79TkmXBEambp"
      },
      "source": [
        "## Store Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2020-06-17T01:35:27.625Z"
        },
        "pycharm": {
          "is_executing": true
        },
        "id": "x-SAXbprambp"
      },
      "source": [
        "pd.DataFrame(results).assign(Data=data_type).to_csv(f'{data_type}.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6zPU4IOambp"
      },
      "source": [
        "## Display Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0-b-cCJambq"
      },
      "source": [
        "Please run the notebook twice as described above under `Usage` to create the two `csv` files with results for different test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2020-06-17T01:35:27.630Z"
        },
        "pycharm": {
          "is_executing": true
        },
        "id": "dJSLAq7Fambq"
      },
      "source": [
        "df = (pd.read_csv('Numeric.csv', index_col=0)\n",
        "      .append(pd.read_csv('Mixed.csv', index_col=0))\n",
        "      .rename(columns=str.capitalize))\n",
        "df.index.name='Storage'\n",
        "df = df.set_index('Data', append=True).unstack()\n",
        "df.Size /= 1e9"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2020-06-17T01:35:27.633Z"
        },
        "pycharm": {
          "is_executing": true
        },
        "scrolled": false,
        "id": "Bm6CdaX3ambq"
      },
      "source": [
        "fig, axes = plt.subplots(ncols=3, figsize=(16, 4))\n",
        "for i, op in enumerate(['Read', 'Write', 'Size']):\n",
        "    flag= op in ['Read', 'Write']\n",
        "    df.loc[:, op].plot.barh(title=op, ax=axes[i], logx=flag)\n",
        "    if flag:\n",
        "        axes[i].set_xlabel('seconds (log scale)')\n",
        "    else:\n",
        "        axes[i].set_xlabel('GB')\n",
        "fig.tight_layout()\n",
        "fig.savefig('storage', dpi=300);"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}